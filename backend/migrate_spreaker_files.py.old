#!/usr/bin/env python3
"""
Migrate audio files from Spreaker to Google Cloud Storage.

This script:
1. Uses Spreaker API to get audio download URLs
2. Downloads audio files from Spreaker
3. Uploads them to your GCS bucket using gcloud CLI
4. Updates the database with new GCS paths
"""

import os
import sys
from pathlib import Path
import subprocess
import argparse
import time
import requests
from typing import Optional

# Add backend directory to path so we can import api modules
backend_dir = Path(__file__).parent.resolve()
if str(backend_dir) not in sys.path:
    sys.path.insert(0, str(backend_dir))

from sqlmodel import Session, select
from api.core.database import engine
from api.models.podcast import Episode, Podcast

# Configuration
TEMP_DOWNLOAD_DIR = Path("./temp_spreaker_downloads")


async def download_file(client: httpx.AsyncClient, url: str, dest_path: Path) -> bool:
    """Download a file from URL to local path."""
    try:
        print(f"Downloading: {url}")
        async with client.stream("GET", url, follow_redirects=True) as response:
            response.raise_for_status()
            dest_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(dest_path, "wb") as f:
                async for chunk in response.aiter_bytes(chunk_size=8192):
                    f.write(chunk)
        
        print(f"  ‚úì Downloaded to: {dest_path}")
        return True
    except Exception as e:
        print(f"  ‚úó Error downloading {url}: {e}")
        return False


def upload_to_gcs(local_path: Path, gcs_path: str, bucket_name: str = GCS_BUCKET_NAME) -> bool:
    """Upload a file to Google Cloud Storage."""
    try:
        print(f"Uploading to GCS: gs://{bucket_name}/{gcs_path}")
        
        storage_client = storage.Client()
        bucket = storage_client.bucket(bucket_name)
        blob = bucket.blob(gcs_path)
        
        # Set content type based on file extension
        content_type = None
        if gcs_path.endswith('.mp3'):
            content_type = 'audio/mpeg'
        elif gcs_path.endswith('.m4a'):
            content_type = 'audio/mp4'
        elif gcs_path.endswith(('.jpg', '.jpeg')):
            content_type = 'image/jpeg'
        elif gcs_path.endswith('.png'):
            content_type = 'image/png'
        
        blob.upload_from_filename(str(local_path), content_type=content_type)
        
        print(f"  ‚úì Uploaded to GCS")
        return True
    except Exception as e:
        print(f"  ‚úó Error uploading to GCS: {e}")
        return False


async def migrate_episode_files(session: Session, episode: Episode, client: httpx.AsyncClient, dry_run: bool = False):
    """Migrate audio and cover image files for a single episode."""
    print(f"\n{'='*80}")
    print(f"Episode: {episode.title} (ID: {episode.id})")
    print(f"{'='*80}")
    
    updated = False
    
    # Migrate audio file
    if episode.audio_url and ("spreaker.com" in episode.audio_url or "api.spreaker.com" in episode.audio_url):
        print(f"\nüéµ Audio file needs migration")
        print(f"  Current URL: {episode.audio_url}")
        
        # Determine file extension from URL or default to .mp3
        file_ext = ".mp3"
        if ".m4a" in episode.audio_url.lower():
            file_ext = ".m4a"
        
        # Create GCS path: episodes/{episode_id}/audio{ext}
        gcs_audio_path = f"episodes/{episode.id}/audio{file_ext}"
        local_audio_path = TEMP_DOWNLOAD_DIR / f"episode_{episode.id}_audio{file_ext}"
        
        if not dry_run:
            # Download from Spreaker
            if await download_file(client, episode.audio_url, local_audio_path):
                # Upload to GCS
                if upload_to_gcs(local_audio_path, gcs_audio_path):
                    # Update database
                    episode.gcs_audio_path = gcs_audio_path
                    
                    # Get file size
                    episode.audio_file_size = local_audio_path.stat().st_size
                    
                    updated = True
                    print(f"  ‚úì Audio migrated to: gs://{GCS_BUCKET_NAME}/{gcs_audio_path}")
                
                # Clean up temp file
                try:
                    local_audio_path.unlink()
                except:
                    pass
        else:
            print(f"  [DRY RUN] Would migrate to: gs://{GCS_BUCKET_NAME}/{gcs_audio_path}")
    else:
        print(f"\nüéµ Audio: Already migrated or no Spreaker URL")
        if episode.gcs_audio_path:
            print(f"  Current GCS path: {episode.gcs_audio_path}")
    
    # Migrate cover image
    if episode.cover_image_url and ("spreaker.com" in episode.cover_image_url or "images.spreaker.com" in episode.cover_image_url):
        print(f"\nüñºÔ∏è  Cover image needs migration")
        print(f"  Current URL: {episode.cover_image_url}")
        
        # Determine file extension
        file_ext = ".jpg"
        if ".png" in episode.cover_image_url.lower():
            file_ext = ".png"
        
        gcs_cover_path = f"episodes/{episode.id}/cover{file_ext}"
        local_cover_path = TEMP_DOWNLOAD_DIR / f"episode_{episode.id}_cover{file_ext}"
        
        if not dry_run:
            # Download from Spreaker
            if await download_file(client, episode.cover_image_url, local_cover_path):
                # Upload to GCS
                if upload_to_gcs(local_cover_path, gcs_cover_path):
                    # Update database
                    episode.gcs_cover_image_path = gcs_cover_path
                    updated = True
                    print(f"  ‚úì Cover migrated to: gs://{GCS_BUCKET_NAME}/{gcs_cover_path}")
                
                # Clean up temp file
                try:
                    local_cover_path.unlink()
                except:
                    pass
        else:
            print(f"  [DRY RUN] Would migrate to: gs://{GCS_BUCKET_NAME}/{gcs_cover_path}")
    else:
        print(f"\nüñºÔ∏è  Cover: Already migrated or no Spreaker URL")
        if episode.gcs_cover_image_path:
            print(f"  Current GCS path: {episode.gcs_cover_image_path}")
    
    if updated and not dry_run:
        session.add(episode)
        session.commit()
        print(f"\n‚úì Database updated for episode {episode.id}")
    
    return updated


async def main(podcast_slug: str = "cinema-irl", dry_run: bool = True):
    """Main migration function."""
    print(f"\n{'='*80}")
    print(f"Spreaker to GCS Migration Tool")
    print(f"{'='*80}")
    print(f"Podcast: {podcast_slug}")
    print(f"Mode: {'DRY RUN (no changes)' if dry_run else 'LIVE (will migrate files)'}")
    print(f"GCS Bucket: {GCS_BUCKET_NAME}")
    print(f"{'='*80}\n")
    
    if not dry_run:
        confirm = input("‚ö†Ô∏è  This will download and migrate files. Continue? (yes/no): ")
        if confirm.lower() != "yes":
            print("Migration cancelled.")
            return
    
    # Create temp directory
    TEMP_DOWNLOAD_DIR.mkdir(exist_ok=True)
    
    async with httpx.AsyncClient(timeout=300.0) as client:
        with Session(engine) as session:
            # Import Podcast model to join
            from api.models.podcast import Podcast
            
            # Get all episodes for the podcast by joining with Podcast table
            statement = select(Episode).join(Podcast).where(
                Podcast.slug == podcast_slug
            ).order_by(desc(Episode.created_at))
            
            episodes = session.exec(statement).all()
            
            if not episodes:
                print(f"‚ùå No episodes found for podcast '{podcast_slug}'")
                return
            
            print(f"Found {len(episodes)} episodes to check\n")
            
            migrated_count = 0
            for episode in episodes:
                if await migrate_episode_files(session, episode, client, dry_run):
                    migrated_count += 1
            
            print(f"\n{'='*80}")
            print(f"Migration Summary")
            print(f"{'='*80}")
            print(f"Total episodes checked: {len(episodes)}")
            print(f"Episodes migrated: {migrated_count}")
            print(f"{'='*80}\n")
    
    # Clean up temp directory
    try:
        TEMP_DOWNLOAD_DIR.rmdir()
    except:
        pass


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Migrate Spreaker files to GCS")
    parser.add_argument("--podcast", default="cinema-irl", help="Podcast slug")
    parser.add_argument("--live", action="store_true", help="Run migration (default is dry-run)")
    
    args = parser.parse_args()
    
    asyncio.run(main(
        podcast_slug=args.podcast,
        dry_run=not args.live
    ))
