import React, { useEffect, useMemo, useRef, useState } from "react";
import { Button } from "@/components/ui/button";
import { Card, CardContent, CardHeader, CardTitle, CardDescription } from "@/components/ui/card";
import { Label } from "@/components/ui/label";
import { Input } from "@/components/ui/input";
import { Select, SelectTrigger, SelectValue, SelectContent, SelectItem } from "@/components/ui/select";
import { ArrowLeft, Mic, Square, Loader2, CheckCircle, Download } from "lucide-react";
import { makeApi } from "@/lib/apiClient";
import { uploadMediaDirect } from "@/lib/directUpload";
import { useToast } from "@/hooks/use-toast";
import { useAuth } from "@/AuthContext";

export default function Recorder({ onBack, token, onFinish, onSaved, source="A" }) {
  const { user: authUser } = useAuth();
  const [isRecording, setIsRecording] = useState(false);
  const [isPaused, setIsPaused] = useState(false);
  const [hasPreview, setHasPreview] = useState(false);
  const [elapsed, setElapsed] = useState(0); // seconds
  const [supportError, setSupportError] = useState("");
  const [devices, setDevices] = useState([]);
  const [selectedDeviceId, setSelectedDeviceId] = useState("");
  const [mimeType, setMimeType] = useState("");
  const [isMicChecking, setIsMicChecking] = useState(false);
  const [micCheckCountdown, setMicCheckCountdown] = useState(0);
  const [micCheckPlayback, setMicCheckPlayback] = useState(false); // New: track playback state
  const [micCheckCompleted, setMicCheckCompleted] = useState(false); // Track if mic check has been done
  const micCheckTimerRef = useRef(null);
  const micCheckAudioRef = useRef(null); // New: reference to playback audio element
  const [levelPct, setLevelPct] = useState(0); // 0..1
  const [levelColor, setLevelColor] = useState('#ef4444'); // Color based on smoothed zones
  const [inputGain, setInputGain] = useState(1.0); // Mic input gain (0.1 to 2.0)
  const gainNodeRef = useRef(null); // GainNode for volume control
  const [micCheckAnalysis, setMicCheckAnalysis] = useState(null); // Analysis results from mic check
  const peakLevelsRef = useRef([]); // Track peak levels during mic check
  const [recordingName, setRecordingName] = useState("");
  const [audioUrl, setAudioUrl] = useState("");
  const [audioBlob, setAudioBlob] = useState(null);
  const [isSaving, setIsSaving] = useState(false);
  const [serverFilename, setServerFilename] = useState("");
  const [serverStem, setServerStem] = useState("");
  const [transcriptReady, setTranscriptReady] = useState(false);
  const [showTimeoutNotice, setShowTimeoutNotice] = useState(false);
  // Display-only name for UX (friendly name + extension), hides server's internal filename
  const [savedDisplayName, setSavedDisplayName] = useState("");
  // Senior-friendly helpers
  const [isCountingDown, setIsCountingDown] = useState(false);
  const [countdown, setCountdown] = useState(0);

  const mediaRecorderRef = useRef(null);
  const streamRef = useRef(null);
  const chunksRef = useRef([]);
  const discardOnStopRef = useRef(false);
  const timerRef = useRef(null);
  const rafRef = useRef(null);
  const audioCtxRef = useRef(null);
  const analyserRef = useRef(null);
  const sourceRef = useRef(null);
  const isRecordingRef = useRef(false);
  const isPausedRef = useRef(false);
  const { toast } = useToast();
  const pollIntervalRef = useRef(null);
  const pollAbortRef = useRef(null);
  const pollStartRef = useRef(0);
  const countdownTimerRef = useRef(null);
  const wakeLockRef = useRef(null);
  const audioRef = useRef(null);
  const isRequestingDevicesRef = useRef(false); // Prevent simultaneous device requests
  const [maxUploadMb, setMaxUploadMb] = useState(500);
  const MAX_UPLOAD_BYTES = useMemo(() => maxUploadMb * 1024 * 1024, [maxUploadMb]);

  const isMobile = useMemo(() => {
    try { return /Mobi|Android|iPhone|iPad|iPod/i.test(navigator.userAgent || ''); } catch { return false; }
  }, []);

  // Generate beep sound for countdown
  const playBeep = (frequency = 800, duration = 150) => {
    try {
      const ctx = new (window.AudioContext || window.webkitAudioContext)();
      const oscillator = ctx.createOscillator();
      const gainNode = ctx.createGain();
      
      oscillator.connect(gainNode);
      gainNode.connect(ctx.destination);
      
      oscillator.frequency.value = frequency;
      oscillator.type = 'sine';
      
      gainNode.gain.setValueAtTime(0.3, ctx.currentTime);
      gainNode.gain.exponentialRampToValueAtTime(0.01, ctx.currentTime + duration / 1000);
      
      oscillator.start(ctx.currentTime);
      oscillator.stop(ctx.currentTime + duration / 1000);
      
      setTimeout(() => {
        try { ctx.close(); } catch {}
      }, duration + 100);
    } catch (e) {
      // Beeps are optional, ignore errors
      console.log('Beep failed:', e);
    }
  };

  useEffect(() => {
    let canceled = false;
    (async () => {
      try {
        const res = await fetch('/api/public/config');
        const data = await res.json().catch(() => ({}));
        const n = parseInt(String(data?.max_upload_mb || '500'), 10);
        if (!canceled && isFinite(n) && !isNaN(n)) {
          const clamped = Math.min(Math.max(n, 10), 2048);
          setMaxUploadMb(clamped);
        }
      } catch {}
    })();
    return () => { canceled = true; };
  }, []);

  const formatTime = (s) => {
    const m = Math.floor(s / 60)
      .toString()
      .padStart(2, "0");
    const r = Math.floor(s % 60)
      .toString()
      .padStart(2, "0");
    return `${m}:${r}`;
  };

  const pickMimeType = () => {
    if (window.MediaRecorder) {
      if (MediaRecorder.isTypeSupported && MediaRecorder.isTypeSupported("audio/webm;codecs=opus")) {
        return "audio/webm;codecs=opus";
      }
      if (MediaRecorder.isTypeSupported && MediaRecorder.isTypeSupported("audio/mp4;codecs=aac")) {
        return "audio/mp4;codecs=aac"; // Safari/iOS
      }
    }
    return "";
  };

  // Re-encode a recording Blob to PCM WAV to normalize timestamps and avoid per-chunk glitches.
  // Returns a Blob of type audio/wav. Throws if decode fails.
  const reencodeToWav = async (blob) => {
    const arrayBuffer = await blob.arrayBuffer();
    const AC = window.AudioContext || window.webkitAudioContext;
    if (!AC) throw new Error("No AudioContext available");
    const ctx = new AC();
    try {
      const audioBuffer = await ctx.decodeAudioData(arrayBuffer);
      const numChannels = Math.min(2, Math.max(1, audioBuffer.numberOfChannels || 1));
      const sampleRate = audioBuffer.sampleRate;
      const length = audioBuffer.length;
      // Prepare interleaved PCM16
      const channelData = [];
      for (let ch = 0; ch < numChannels; ch++) {
        channelData[ch] = audioBuffer.getChannelData(ch);
      }
      const bytesPerSample = 2;
      const blockAlign = numChannels * bytesPerSample;
      const byteRate = sampleRate * blockAlign;
      const dataSize = length * blockAlign;
      const buffer = new ArrayBuffer(44 + dataSize);
      const view = new DataView(buffer);

      // Write WAV header
      let offset = 0;
      // RIFF identifier 'RIFF'
      view.setUint32(offset, 0x52494646, false); offset += 4;
      // file length minus RIFF and size fields
      view.setUint32(offset, 36 + dataSize, true); offset += 4;
      // RIFF type 'WAVE'
      view.setUint32(offset, 0x57415645, false); offset += 4;
      // format chunk identifier 'fmt '
      view.setUint32(offset, 0x666d7420, false); offset += 4;
      // format chunk length
      view.setUint32(offset, 16, true); offset += 4;
      // audio format (1 = PCM)
      view.setUint16(offset, 1, true); offset += 2;
      // number of channels
      view.setUint16(offset, numChannels, true); offset += 2;
      // sample rate
      view.setUint32(offset, sampleRate, true); offset += 4;
      // byte rate (sample rate * block align)
      view.setUint32(offset, byteRate, true); offset += 4;
      // block align (channel count * bytes per sample)
      view.setUint16(offset, blockAlign, true); offset += 2;
      // bits per sample
      view.setUint16(offset, 16, true); offset += 2;
      // data chunk identifier 'data'
      view.setUint32(offset, 0x64617461, false); offset += 4;
      // data chunk length
      view.setUint32(offset, dataSize, true); offset += 4;

      // PCM samples
      const writeSample = (v) => {
        // Clamp to [-1,1] then scale to 16-bit PCM
        const s = Math.max(-1, Math.min(1, v));
        view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7fff, true);
        offset += 2;
      };

      if (numChannels === 1) {
        const input = channelData[0];
        for (let i = 0; i < length; i++) writeSample(input[i]);
      } else {
        for (let i = 0; i < length; i++) {
          for (let ch = 0; ch < numChannels; ch++) writeSample(channelData[ch][i]);
        }
      }

      const wavBlob = new Blob([buffer], { type: "audio/wav" });
      try { ctx.close(); } catch {}
      return wavBlob;
    } finally {
      try { ctx.close(); } catch {}
    }
  };

  const extractStemFromFilename = (filename) => {
    if (!filename) return "";
    const idx = filename.lastIndexOf(".");
    return idx > 0 ? filename.slice(0, idx) : filename;
  };

  const stopStream = () => {
    try {
      if (streamRef.current) {
        streamRef.current.getTracks().forEach((t) => t.stop());
      }
    } catch {}
    streamRef.current = null;
  };

  const stopAudioGraph = () => {
    try {
      if (rafRef.current) cancelAnimationFrame(rafRef.current);
      rafRef.current = null;
      if (audioCtxRef.current) audioCtxRef.current.close();
    } catch {}
    audioCtxRef.current = null;
    analyserRef.current = null;
    sourceRef.current = null;
    gainNodeRef.current = null;
  };

  const updateGain = (newGain) => {
    setInputGain(newGain);
    if (gainNodeRef.current) {
      gainNodeRef.current.gain.value = newGain;
    }
    // Persist to localStorage
    try { localStorage.setItem('ppp_mic_gain', String(newGain)); } catch {}
  };

  const analyzeMicCheckLevels = (peakLevels, currentGain) => {
    // Count how many samples show meaningful audio activity
    const avg = peakLevels.reduce((a, b) => a + b, 0) / peakLevels.length;
    const max = Math.max(...peakLevels);
    
    // Count samples above various thresholds
    const samplesAbove5 = peakLevels.filter(p => p > 0.05).length;
    const samplesAbove10 = peakLevels.filter(p => p > 0.10).length;
    const samplesAbove50 = peakLevels.filter(p => p > 0.50).length;
    
    console.log('[MicCheck Analysis] Avg:', avg.toFixed(3), 'Max:', max.toFixed(3), 
                'Samples >5%:', samplesAbove5, '>10%:', samplesAbove10, '>50%:', samplesAbove50);
    
    let status = 'good';
    let message = '';
    let suggestion = '';
    let suggestedGain = currentGain;
    let requireRedo = false;
    
    // Silence: Very low max AND very few samples above 5%
    if (max < 0.05 || samplesAbove5 < 10) {
      status = 'silent';
      message = 'üîá No audio detected';
      suggestion = 'Your microphone appears to be muted or unplugged.\n\n‚Ä¢ Check Windows Sound Settings\n‚Ä¢ Make sure the microphone isn\'t muted\n‚Ä¢ Try unplugging and replugging the mic';
      requireRedo = true;
    } 
    // Too quiet: Some audio but consistently very low
    else if (max < 0.15 && avg < 0.05) {
      status = 'too_quiet';
      message = 'üîâ Microphone is too quiet';
      suggestion = 'We can barely hear you.\n\n‚Ä¢ In Windows Sound Settings, increase microphone volume to 70-80%\n‚Ä¢ Speak closer to the microphone\n‚Ä¢ Make sure you\'re using the right microphone input';
      requireRedo = true;
    }
    // Clipping: Too many samples hitting the ceiling
    else if (samplesAbove50 > peakLevels.length * 0.3 || max > 0.95) {
      status = 'clipping';
      message = '‚ö†Ô∏è Audio is too loud (distorting)';
      suggestion = 'Your audio is clipping and will sound distorted.\n\n‚Ä¢ In Windows Sound Settings, reduce microphone volume to 40-60%\n‚Ä¢ Move back from the microphone\n‚Ä¢ Speak a bit more softly';
      requireRedo = true;
    }
    // Good: Audio is present and reasonable
    else {
      status = 'good';
      message = '‚úÖ Microphone is working!';
      suggestion = 'We can hear you clearly. You\'re ready to start recording.\n\nThe audio will be professionally processed and optimized when you finish your episode.';
    }
    
    return {
      status,
      message,
      suggestion,
      suggestedGain,
      requireRedo,
      stats: { avg, max, min: Math.min(...peakLevels) }
    };
  };

  const buildAudioGraph = (stream) => {
    try {
      console.log('[AudioGraph] Building audio graph for stream:', stream);
      const ctx = new (window.AudioContext || window.webkitAudioContext)();
      const source = ctx.createMediaStreamSource(stream);
      const gainNode = ctx.createGain();
      const analyser = ctx.createAnalyser();
      analyser.fftSize = 2048;
      console.log('[AudioGraph] Created AudioContext, analyser, gain node');
      
      // Connect: source -> gain -> analyser
      source.connect(gainNode);
      gainNode.connect(analyser);
      gainNode.gain.value = inputGain;
      
      audioCtxRef.current = ctx;
      analyserRef.current = analyser;
      sourceRef.current = source;
      gainNodeRef.current = gainNode;

      const data = new Uint8Array(analyser.fftSize);
      let smoothedLevel = 0; // Smoothed level for display
      const smoothingFactor = 0.08; // Lower = smoother (range 0-1)
      let frameCount = 0; // Only update color every N frames
      
      const loop = () => {
        if (!analyserRef.current) {
          console.log('[AudioGraph] Loop stopped - analyser gone');
          return; // Stop if analyser is gone
        }
        
        analyser.getByteTimeDomainData(data);
        
        // Compute simple peak level 0..1
        let peak = 0;
        for (let i = 0; i < data.length; i++) {
          const v = Math.abs(data[i] - 128) / 128; // center at 0
          if (v > peak) peak = v;
        }
        
        // Track raw peak levels during mic check for analysis (every 10th frame to avoid too many samples)
        if (frameCount % 10 === 0 && peakLevelsRef.current) {
          peakLevelsRef.current.push(peak);
        }
        
        // Exponential smoothing: gradually move toward peak
        // If peak is higher, move up faster; if lower, decay slower
        if (peak > smoothedLevel) {
          smoothedLevel = smoothedLevel + (peak - smoothedLevel) * 0.3; // Rise faster
        } else {
          smoothedLevel = smoothedLevel + (peak - smoothedLevel) * smoothingFactor; // Decay slower
        }
        
        // Visual boost: Scale up for visibility (2.5x makes typical speech fill the bar nicely)
        // Raw audio is usually 10-40%, so we multiply to make it 25-100% on the visual meter
        const boostedLevel = Math.min(1, smoothedLevel * 2.5);
        setLevelPct(boostedLevel);
        
        // Debug: Log boosted level every 30 frames
        if (frameCount % 30 === 0) {
          console.log('[AudioGraph] Peak:', peak.toFixed(3), 'Smoothed:', smoothedLevel.toFixed(3), 'Boosted:', boostedLevel.toFixed(3), 'Pct will be:', (boostedLevel * 100).toFixed(1) + '%');
        }
        
        // Bright color when audio detected, dark when silent
        frameCount++;
        if (frameCount >= 20) {
          frameCount = 0;
          // Cyan/blue when audio present, dark gray when silent
          const newColor = boostedLevel > 0.15 ? '#06b6d4' : '#374151'; // cyan-500 or gray-700
          setLevelColor(newColor);
        }
        
        rafRef.current = requestAnimationFrame(loop);
      };
      
      console.log('[AudioGraph] Starting animation frame loop');
      rafRef.current = requestAnimationFrame(loop);
    } catch (e) {
      console.error('[AudioGraph] Failed to build:', e);
      // Meter optional; ignore failures
    }
  };

  const ensurePermissionAndDevices = async () => {
    // Prevent simultaneous requests
    if (isRequestingDevicesRef.current) {
      console.log('[Recorder] Already requesting devices, skipping...');
      return;
    }
    
    isRequestingDevicesRef.current = true;
    
    // Request minimal audio to unlock enumerateDevices
    try {
      // Clear any previous error when trying again
      setSupportError("");
      
      console.log('[Recorder] Requesting microphone access...');
      const constraints = { audio: true };
      const s = await navigator.mediaDevices.getUserMedia(constraints);
      console.log('[Recorder] Got media stream, enumerating devices...');
      
      try {
        const devs = await navigator.mediaDevices.enumerateDevices();
        console.log('[Recorder] Found devices:', devs.length, 'total');
        console.log('[Recorder] Raw audio inputs:', devs.filter(d => d.kind === "audioinput").map(d => ({ 
          id: d.deviceId?.slice(0, 30) || 'EMPTY', 
          label: d.label || 'NO_LABEL' 
        })));
        
        // Only include devices with a non-empty deviceId; some browsers obfuscate until permission is granted
        const inputs = devs.filter((d) => d.kind === "audioinput" && d.deviceId).map((d)=>{
          // Clean trailing hex noise if present in label (e.g., "USB Mic (abcd:1234)")
          const clean = (d.label || '').replace(/\s*\([0-9a-f]{4}:[0-9a-f]{4}\)$/i, '').trim();
          // Explicitly copy properties since MediaDeviceInfo properties are getters
          return { 
            deviceId: d.deviceId,
            kind: d.kind,
            label: clean || d.label,
            groupId: d.groupId
          };
        });
        
        console.log('[Recorder] Found audio inputs:', inputs.length, inputs.map(d => d.label || d.deviceId));
        console.log('[Recorder] First device object:', inputs[0]);
        setDevices(inputs);
        
        // Auto-select first device if none selected, or restore from localStorage
        if (inputs.length > 0) {
          let saved = '';
          try { saved = localStorage.getItem('ppp_mic_device_id') || ''; } catch {}
          
          let deviceToSelect = null;
          if (saved && inputs.find(d => d.deviceId === saved)) {
            console.log('[Recorder] Restoring saved device:', saved);
            deviceToSelect = saved;
          } else {
            // Always select first device (don't check selectedDeviceId due to closure issues)
            console.log('[Recorder] Auto-selecting first device:', inputs[0].deviceId);
            deviceToSelect = inputs[0].deviceId;
          }
          
          if (deviceToSelect) {
            setSelectedDeviceId(deviceToSelect);
          }
        } else {
          console.warn('[Recorder] No audio input devices found after enumeration');
        }
      } finally {
        try { s.getTracks().forEach((t) => t.stop()); } catch {}
      }
    } catch (e) {
      console.error('[Recorder] Failed to get microphone access:', e);
      const name = e?.name || "";
      if (name === "NotAllowedError" || name === "SecurityError" || name === "PermissionDeniedError") {
        setSupportError("Microphone access was blocked. Please allow microphone permission in your browser, then try again. Tip: Click the mic/camera icon in the address bar to grant access.");
      } else if (name === "NotFoundError") {
        setSupportError("No microphone was found. Plug in or enable a microphone and try again.");
      } else {
        setSupportError("Could not access microphone.");
      }
      throw e;
    } finally {
      isRequestingDevicesRef.current = false;
    }
  };

  const startStream = async (deviceId) => {
    // Be resilient: some devices reject certain constraints; try a few fallbacks
    const attempts = [];
    const withDev = deviceId ? { exact: deviceId } : undefined;
    attempts.push({ audio: { deviceId: withDev, channelCount: 1, noiseSuppression: { ideal: true }, echoCancellation: { ideal: true } } });
    attempts.push({ audio: { deviceId: withDev, channelCount: 1 } });
    attempts.push({ audio: { deviceId: withDev } });
    attempts.push({ audio: true });

    let lastErr;
    for (const c of attempts) {
      try {
        const s = await navigator.mediaDevices.getUserMedia(c);
        streamRef.current = s;
        buildAudioGraph(s);
        return s;
      } catch (e) {
        lastErr = e;
        // Continue to next fallback
      }
    }
    throw lastErr || new Error('getUserMedia failed');
  };

  const startRecording = async () => {
    setSupportError("");
    setAudioUrl((prev) => {
      if (prev) URL.revokeObjectURL(prev);
      return "";
    });
    setAudioBlob(null);
    setHasPreview(false);
    setElapsed(0);
  // Reset any existing chunks to avoid concatenating from a previous session
  chunksRef.current = [];
  // Ensure preview audio is paused so it won't play while recording (prevents echo)
  try { if (audioRef.current) { audioRef.current.pause(); audioRef.current.currentTime = 0; } } catch {}
    setIsPaused(false);
    isPausedRef.current = false;

    const m = pickMimeType();
    if (!m) {
      setSupportError("Recording not supported in this browser.");
      return;
    }
    setMimeType(m);

    try {
      if (!navigator.mediaDevices?.getUserMedia) {
        setSupportError("Recording not supported in this browser.");
        return;
      }
      // Start stream with current device
      const s = await startStream(selectedDeviceId);

      const rec = new MediaRecorder(s, { mimeType: m });
      chunksRef.current = [];
  let lastChunkAt = 0;
  rec.ondataavailable = (e) => {
        const now = Date.now();
        // Only accept non-empty chunks while the session is active; debounce to avoid quick duplicates
        if (!e?.data || e.data.size === 0) return;
        if (now - lastChunkAt < 50) return; // guard against immediate duplicate events
        lastChunkAt = now;
        chunksRef.current.push(e.data);
      };
      rec.onpause = () => {
        setIsPaused(true);
        isPausedRef.current = true;
      };
      rec.onresume = () => {
        setIsPaused(false);
        isPausedRef.current = false;
      };
      rec.onstop = () => {
        // Allow any final ondataavailable to land before assembling
        Promise.resolve().then(async () => {
          try {
            if (discardOnStopRef.current) {
              // Discard short take
              chunksRef.current = [];
              discardOnStopRef.current = false;
              setHasPreview(false);
              setAudioBlob(null);
              setAudioUrl((u)=>{ if(u) URL.revokeObjectURL(u); return ""; });
              setRecordingName("");
              setElapsed(0);
              toast({ title: 'Discarded', description: 'Short take discarded (<30s).' });
              return;
            }
            const parts = chunksRef.current || [];
            const rawBlob = new Blob(parts, { type: m });
            // Re-encode to WAV to normalize and remove any duplicated 1s chunk artifacts
            let finalBlob = rawBlob;
            try {
              finalBlob = await reencodeToWav(rawBlob);
              setMimeType("audio/wav");
            } catch (err) {
              // Fallback to original if re-encode fails
              finalBlob = rawBlob;
            }
            setAudioBlob(finalBlob);
            const url = URL.createObjectURL(finalBlob);
            setAudioUrl(url);
            setHasPreview(true);
          } catch {}
        });
      };
  mediaRecorderRef.current = rec;
  // Start without a timeSlice so data is emitted on stop (and occasionally on pause/resume).
  // This avoids per-second chunk artifacts some browsers exhibit when concatenating.
  rec.start();
      setIsRecording(true);
      isRecordingRef.current = true;
      // Timer
      if (timerRef.current) { try { clearInterval(timerRef.current); } catch {} }
      timerRef.current = setInterval(() => {
        if (isRecordingRef.current && !isPausedRef.current) {
          setElapsed((e) => e + 1);
        }
      }, 1000);
      // Try to keep the screen awake during recording (ignore errors)
      try {
        if (navigator.wakeLock?.request) {
          wakeLockRef.current = await navigator.wakeLock.request('screen');
        }
      } catch {}
    } catch (e) {
      console.error(e);
      const name = e?.name || "";
      if (name === "NotAllowedError" || name === "SecurityError" || name === "PermissionDeniedError") {
        setSupportError("Microphone permission denied. Allow access in your browser and try again.");
      } else if (name === "NotFoundError") {
        setSupportError("No microphone detected.");
      } else {
        setSupportError("Could not access microphone.");
      }
      stopStream();
      stopAudioGraph();
    }
  };

  const stopRecording = () => {
    try {
      if (mediaRecorderRef.current && mediaRecorderRef.current.state !== "inactive") {
  mediaRecorderRef.current.stop();
      }
    } catch {}
    setIsRecording(false);
  isRecordingRef.current = false;
  setIsPaused(false);
  isPausedRef.current = false;
    if (timerRef.current) clearInterval(timerRef.current);
    timerRef.current = null;
  // Stop any preview playback immediately to avoid overlapping sound
  try { if (audioRef.current) audioRef.current.pause(); } catch {}
    stopAudioGraph();
    stopStream();
  // Release wake lock if held
  try { if (wakeLockRef.current?.release) { wakeLockRef.current.release(); } } catch {}
  wakeLockRef.current = null;
  };

  const startCountdown = () => {
    if (isRecording || isCountingDown) return;
    setCountdown(3);
    setIsCountingDown(true);
    playBeep(800, 150); // Initial beep for 3
    if (countdownTimerRef.current) { try { clearInterval(countdownTimerRef.current); } catch {} }
    countdownTimerRef.current = setInterval(() => {
      setCountdown((c) => {
        if (c <= 1) {
          try { clearInterval(countdownTimerRef.current); } catch {}
          countdownTimerRef.current = null;
          setIsCountingDown(false);
          startRecording();
          return 0;
        }
        playBeep(800, 150); // Beep for each countdown number
        return c - 1;
      });
    }, 1000);
  };

  const startResumeCountdown = () => {
    if (!isPaused || isCountingDown) return;
    setCountdown(3);
    setIsCountingDown(true);
    playBeep(800, 150); // Initial beep for 3
    if (countdownTimerRef.current) { try { clearInterval(countdownTimerRef.current); } catch {} }
    countdownTimerRef.current = setInterval(() => {
      setCountdown((c) => {
        if (c <= 1) {
          try { clearInterval(countdownTimerRef.current); } catch {}
          countdownTimerRef.current = null;
          setIsCountingDown(false);
          try { mediaRecorderRef.current?.resume?.(); } catch {}
          return 0;
        }
        playBeep(800, 150); // Beep for each countdown number
        return c - 1;
      });
    }, 1000);
  };

  const cancelCountdown = () => {
    try { if (countdownTimerRef.current) clearInterval(countdownTimerRef.current); } catch {}
    countdownTimerRef.current = null;
    setIsCountingDown(false);
    setCountdown(0);
  };

  const handleRecordToggle = () => {
    // Three-state button: Record (initial) -> Pause -> Resume (with 3s countdown)
    if (!isRecording) {
      if (isCountingDown) { cancelCountdown(); return; }
      startCountdown();
      return;
    }
    // If currently recording and not paused, pause immediately
    if (!isPaused) {
      try { mediaRecorderRef.current?.pause?.(); } catch {}
      return;
    }
    // If paused, resume with countdown
    startResumeCountdown();
  };

  const handleStop = () => {
    if (isPaused) {
      // If less than 30 seconds captured, warn that stopping will discard
      if (elapsed < 30) {
        const ok = window.confirm('You have recorded less than 30 seconds. Stopping now will discard this take. Do you want to stop and discard?');
        if (!ok) return;
        discardOnStopRef.current = true;
      }
      stopRecording();
    }
  };

  const handleMicCheck = async () => {
    if (isRecording || isMicChecking) return;
    setIsMicChecking(true);
    setMicCheckPlayback(false);
    setMicCheckAnalysis(null); // Clear previous analysis
    try {
      // Clean up any existing audio graph before starting
      stopAudioGraph();
      stopStream();
      
      // Ensure we can see devices; if permission was revoked mid-session, prompt again
      if (!devices || devices.length === 0) {
        try { await ensurePermissionAndDevices(); } catch {}
      }
      
      // 3-2-1 countdown with beeps BEFORE starting mic check
      for (let i = 3; i > 0; i--) {
        setMicCheckCountdown(i);
        playBeep(800, 150); // Beep sound
        await new Promise(resolve => setTimeout(resolve, 1000));
      }
      
      const s = await startStream(selectedDeviceId);
      
      // Small delay to let audio graph initialize
      await new Promise(resolve => setTimeout(resolve, 100));
      
      // Reset peak tracking for this mic check
      peakLevelsRef.current = [];
      
      // Start recording FIRST, then do countdown
      const dest = audioCtxRef.current?.createMediaStreamDestination?.();
      if (dest && gainNodeRef.current) {
        // Connect gain node to destination for recording (it's already connected to analyser for meter)
        gainNodeRef.current.connect(dest);
        const rec = new MediaRecorder(dest.stream);
        const chunks = [];
        
        rec.ondataavailable = (e) => { if (e.data?.size) chunks.push(e.data); };
        rec.start();
        
        // Countdown from 5 to 0 during recording (5 seconds total, plus 0.5s buffer)
        for (let i = 5; i > 0; i--) {
          setMicCheckCountdown(-i); // Negative numbers indicate recording countdown
          await new Promise(resolve => setTimeout(resolve, 1000));
        }
        setMicCheckCountdown(0); // Recording complete
        
        // Extra 500ms buffer to catch the last word/number
        await new Promise(resolve => setTimeout(resolve, 500));
        
        // Stop recording after countdown finishes
        try { rec.stop(); } catch {}
        
        // Wait for the recording to be fully processed
        const recordedChunks = await new Promise((resolve) => {
          rec.onstop = () => resolve(chunks);
          // Fallback timeout in case onstop doesn't fire
          setTimeout(() => resolve(chunks), 500);
        });
        
        // Playback the full recording
        setMicCheckPlayback(true);
        const blob = new Blob(recordedChunks, { type: 'audio/webm' });
        const url = URL.createObjectURL(blob);
        const a = new Audio(url);
        micCheckAudioRef.current = a;
        
        // Wait for playback to complete
        await new Promise((resolve) => {
          a.onended = () => { 
            try { URL.revokeObjectURL(url); } catch {} 
            resolve();
          };
          a.onerror = () => {
            try { URL.revokeObjectURL(url); } catch {}
            resolve();
          };
          a.play().catch(() => resolve());
        });
        
        // Analyze the recorded levels
        if (peakLevelsRef.current.length > 0) {
          const analysis = analyzeMicCheckLevels(peakLevelsRef.current, inputGain);
          setMicCheckAnalysis(analysis);
          
          // Auto-adjust gain if suggested
          if (analysis.suggestedGain !== inputGain && !analysis.requireRedo) {
            updateGain(analysis.suggestedGain);
          }
          
          // If redo required, don't mark as completed
          if (!analysis.requireRedo) {
            setMicCheckCompleted(true);
          }
        } else {
          // No data collected, mark as completed anyway
          setMicCheckCompleted(true);
        }
      }
      
      stopAudioGraph();
      s.getTracks().forEach((t) => t.stop());
    } catch (e) {
      const name = e?.name || '';
      if (name === 'NotAllowedError' || name === 'SecurityError' || name === 'PermissionDeniedError') {
        setSupportError('Microphone permission is blocked. Allow access in your browser and try again.');
      } else if (name === 'NotFoundError' || name === 'OverconstrainedError') {
        setSupportError('Could not start mic check for the selected device. Try another microphone or unplug/replug it.');
      } else {
        setSupportError('Could not start mic check.');
      }
    } finally {
      setIsMicChecking(false);
      setMicCheckCountdown(0);
      setMicCheckPlayback(false);
      // Don't auto-mark as completed here - let the analysis decide
      micCheckAudioRef.current = null;
    }
  };

  const ensureExt = (name, ext) => {
    if (!name) return `untitled${ext}`;
    const lower = name.toLowerCase();
    return lower.endsWith(ext) ? name : `${name}${ext}`;
  };

  const formatDateName = () => {
    const now = new Date();
    const year = now.getFullYear();
    const month = String(now.getMonth() + 1).padStart(2, '0');
    const day = String(now.getDate()).padStart(2, '0');
    const hours = String(now.getHours()).padStart(2, '0');
    const minutes = String(now.getMinutes()).padStart(2, '0');
    const seconds = String(now.getSeconds()).padStart(2, '0');
    return `recording_${year}-${month}-${day}_${hours}-${minutes}-${seconds}`;
  };

  const handleSave = async () => {
    if (!audioBlob || isSaving) return;
    if (audioBlob.size > MAX_UPLOAD_BYTES) {
      toast({ variant: "destructive", title: "Too large", description: "Recording too long to upload (over 500 MB)." });
      return;
    }
    if (serverFilename) {
      // Already uploaded; keep UI idempotent
      return;
    }
    try {
      setIsSaving(true);
  // Determine final name
  const baseName = (recordingName && recordingName.trim()) ? recordingName.trim() : formatDateName();
  let ext = ".webm";
  if (mimeType.includes("wav")) ext = ".wav";
  else if (mimeType.includes("webm")) ext = ".webm";
  else if (mimeType.includes("mp4") || mimeType.includes("aac")) ext = ".m4a";
      const filenameWithExt = ensureExt(baseName, ext);
  // Save display name immediately for UI; we keep server filename internally
  setSavedDisplayName(filenameWithExt);
      // Build File from Blob so server receives a filename with extension
      const file = new File([audioBlob], filenameWithExt, { type: mimeType || audioBlob.type || "audio/webm" });
      
      // Get user email for notification
      const userEmail = authUser?.email || '';
      
      const uploaded = await uploadMediaDirect({
        category: 'main_content',
        file,
        friendlyName: baseName,
        token,
        notifyWhenReady: !!userEmail,
        notifyEmail: userEmail || undefined,
      });
      const first = Array.isArray(uploaded) ? uploaded[0] : null;
      const stored = first && (first.filename || first.name || first.stored_name);
      if (!stored) throw new Error("Upload response missing filename");
      setServerFilename(stored);
      setServerStem(extractStemFromFilename(stored));
      
      // Surface success toast with email confirmation
      const emailMsg = userEmail 
        ? ` We'll email you at ${userEmail} when it's ready.` 
        : '';
      toast({ 
        title: "Recording Saved!", 
        description: `Transcription started.${emailMsg} Download link available for 24 hours.` 
      });
  // Notify host app (Plus Plus workspace upload screen, etc.) so it can surface the new media immediately
  try { window.dispatchEvent(new CustomEvent('ppp:media-uploaded', { detail: first })); } catch {}
  try { if (typeof onSaved === 'function') onSaved(first); } catch {}
    } catch (e) {
      const msg = (e && (e.detail || e.message)) || "Upload failed";
      toast({ variant: "destructive", title: "Upload error", description: msg });
    } finally {
      setIsSaving(false);
    }
  };

  // Populate devices after permission when component mounts (lazy: on first record or mic check).
  useEffect(() => {
    let mounted = true;
    
    // Load saved gain from localStorage
    try {
      const savedGain = localStorage.getItem('ppp_mic_gain');
      if (savedGain) {
        const gainValue = parseFloat(savedGain);
        if (!isNaN(gainValue) && gainValue >= 0.1 && gainValue <= 2.0) {
          setInputGain(gainValue);
        }
      }
    } catch {}
    
    // Try to enumerate if permission already granted
    (async () => {
      try {
        if (!mounted) return;
        console.log('[Recorder Mount] Starting device detection...');
        
        // Check if permission already granted
        let permissionGranted = false;
        if (navigator.permissions?.query) {
          try {
            const status = await navigator.permissions.query({ name: "microphone" });
            console.log('[Recorder Mount] Microphone permission status:', status?.state);
            permissionGranted = status?.state === "granted";
            
            if (status?.state === "denied") {
              setSupportError("Microphone access is blocked. Enable it in your browser site settings, then press Record.");
              return; // Don't try to enumerate if denied
            }
          } catch (e) {
            console.log('[Recorder Mount] Permissions API query failed:', e);
            // Permissions API not supported or failed - continue anyway
          }
        }
        
        // If permission already granted, request devices properly
        // (enumerateDevices doesn't populate deviceIds until getUserMedia called)
        if (permissionGranted && mounted) {
          console.log('[Recorder Mount] Permission already granted, requesting devices...');
          try {
            await ensurePermissionAndDevices();
            return; // Success - ensurePermissionAndDevices handles everything
          } catch (e) {
            console.error('[Recorder Mount] ensurePermissionAndDevices failed:', e);
          }
        }
        
        // No permission yet - wait for user to click Record or Allow Access button
        console.log('[Recorder Mount] No permission granted yet - waiting for user action');
        
      } catch (e) {
        console.error('[Recorder Mount] Failed during mount:', e);
      }
    })();
    
    return () => {
      mounted = false;
      // Cleanup on unmount
      try { if (timerRef.current) clearInterval(timerRef.current); } catch {}
      try { if (countdownTimerRef.current) clearInterval(countdownTimerRef.current); } catch {}
      stopAudioGraph();
      stopStream();
      if (audioUrl) URL.revokeObjectURL(audioUrl);
      try { if (pollIntervalRef.current) clearInterval(pollIntervalRef.current); } catch {}
      try { if (pollAbortRef.current) pollAbortRef.current.abort(); } catch {}
      try { if (wakeLockRef.current?.release) { wakeLockRef.current.release(); } } catch {}
    };
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  // Start polling transcript readiness once we have a stored filename/stem
  useEffect(() => {
    // Reset readiness states when stem changes
    setTranscriptReady(false);
    setShowTimeoutNotice(false);
    if (!serverStem) {
      // Clear any existing polling
      try { if (pollIntervalRef.current) clearInterval(pollIntervalRef.current); } catch {}
      try { if (pollAbortRef.current) pollAbortRef.current.abort(); } catch {}
      pollIntervalRef.current = null;
      pollAbortRef.current = null;
      return;
    }

    const api = makeApi(token);
    const TEN_MIN_MS = 10 * 60 * 1000;
    pollStartRef.current = Date.now();

    const check = async () => {
      // Abort any in-flight
      try { if (pollAbortRef.current) pollAbortRef.current.abort(); } catch {}
      const controller = new AbortController();
      pollAbortRef.current = controller;
      try {
        const res = await api.get(`/api/ai/transcript-ready?hint=${encodeURIComponent(serverStem)}`, { signal: controller.signal });
        const ready = (res && (res.ready === true || res.status === 'ready' || res === true));
        if (ready) {
          setTranscriptReady(true);
          try { if (pollIntervalRef.current) clearInterval(pollIntervalRef.current); } catch {}
          pollIntervalRef.current = null;
        }
      } catch (e) {
        // Ignore transient errors; continue polling
      }
      const elapsedMs = Date.now() - pollStartRef.current;
      if (elapsedMs >= TEN_MIN_MS) setShowTimeoutNotice(true);
    };

    // Kick off immediately, then every 5s
    check();
    pollIntervalRef.current = setInterval(check, 5000);

    return () => {
      try { if (pollIntervalRef.current) clearInterval(pollIntervalRef.current); } catch {}
      pollIntervalRef.current = null;
      try { if (pollAbortRef.current) pollAbortRef.current.abort(); } catch {}
      pollAbortRef.current = null;
    };
  }, [serverStem, token]);

  // Keyboard shortcut: Space to start/stop recording (when not typing)
  useEffect(() => {
    const isEditable = (el) => {
      if (!el) return false;
      const tn = el.tagName?.toLowerCase();
      return el.isContentEditable || tn === 'input' || tn === 'textarea' || tn === 'select';
    };
    const onKey = (e) => {
      if (e.ctrlKey || e.metaKey || e.altKey) return;
      if (isEditable(e.target)) return; // Don't intercept if user is typing
      
      const key = e.key || e.code;
      // Space triggers record/pause/resume
      if (key === ' ' || key === 'Spacebar' || key === 'Space') {
        e.preventDefault();
        handleRecordToggle();
      }
    };
    window.addEventListener('keydown', onKey);
    return () => window.removeEventListener('keydown', onKey);
  }, [handleRecordToggle]);

  const onChangeDevice = async (value) => {
    setSelectedDeviceId(value);
  try { localStorage.setItem('ppp_mic_device_id', value || ''); } catch {}
    // If we already have permission and not recording, pre-warm a silent stream for meter readiness
    if (!isRecording) {
      try {
        stopAudioGraph();
        stopStream();
        const s = await startStream(value);
        // Don't keep it forever; just build graph to show signal then stop after brief delay
        setTimeout(() => {
          stopAudioGraph();
          try { s.getTracks().forEach((t) => t.stop()); } catch {}
        }, 500);
      } catch {}
    } else {
      // Restart stream during recording (simple approach: stop recording)
      stopRecording();
      // Optionally auto-restart with new device
  startCountdown();
    }
  };

  return (
    <>
      <style>{`
        /* Custom slider styling */
        input[type="range"].slider {
          -webkit-appearance: none;
          appearance: none;
        }
        input[type="range"].slider::-webkit-slider-thumb {
          -webkit-appearance: none;
          appearance: none;
          width: 20px;
          height: 20px;
          border-radius: 50%;
          background: #2563eb;
          cursor: pointer;
          box-shadow: 0 2px 4px rgba(0,0,0,0.2);
        }
        input[type="range"].slider::-moz-range-thumb {
          width: 20px;
          height: 20px;
          border-radius: 50%;
          background: #2563eb;
          cursor: pointer;
          border: none;
          box-shadow: 0 2px 4px rgba(0,0,0,0.2);
        }
        input[type="range"].slider::-webkit-slider-runnable-track {
          height: 8px;
          border-radius: 4px;
        }
        input[type="range"].slider::-moz-range-track {
          height: 8px;
          border-radius: 4px;
        }
      `}</style>
      <div className="space-y-6">
        {/* Top bar */}
        <div className="flex items-center gap-3">
    <Button variant="ghost" onClick={onBack} className="px-2 focus-visible:ring-2 focus-visible:ring-offset-2 focus-visible:ring-primary" aria-label="Go back to dashboard">
            <ArrowLeft className="w-4 h-4 mr-2" /> Back
          </Button>
        <div>
          <h1 className="text-2xl font-semibold">Record an Episode</h1>
          {/* SuperAdmin-only: Show internal routing path for debugging */}
          {authUser?.role === 'superadmin' && (
            <p className="text-sm text-muted-foreground">{source === 'A' ? 'Capture audio directly in your browser and edit it afterwards' : 'Capture audio directly in your browser and save it to your library.'}</p>
          )}
        </div>
      </div>

      <Card className="shadow-sm">
        <CardHeader className="pb-2">
          <CardTitle className="text-lg">Recorder</CardTitle>
          <CardDescription>
            Press the circle to record, press again to pause, click stop while paused to end recording.
            <span className="block text-xs text-muted-foreground mt-1">
              üí° Tip: Press <kbd className="px-1 py-0.5 text-xs bg-muted border rounded">Space</kbd> to start/pause recording
            </span>
          </CardDescription>
        </CardHeader>
        <CardContent className="space-y-6">
          {/* Mic check full-screen overlay when active OR showing analysis results */}
          {(isMicChecking || micCheckAnalysis) ? (
            <div className="min-h-[600px] flex flex-col items-center justify-center space-y-8">
              {!micCheckAnalysis && (
                <div className="bg-blue-50 border-4 border-blue-400 rounded-2xl p-12 text-center max-w-2xl mx-auto shadow-lg" aria-live="polite">
                  {micCheckCountdown > 0 && (
                  <>
                    <div className="text-3xl font-bold text-blue-900 mb-4">
                      Get Ready...
                    </div>
                    <div className="text-8xl font-mono font-bold text-blue-600 mb-6">
                      {micCheckCountdown}
                    </div>
                    <p className="text-xl text-blue-700 mb-8">
                      Starting mic check in {micCheckCountdown}...<br />
                      <span className="text-base">Listen for the beeps!</span>
                    </p>
                  </>
                  )}
                  {micCheckCountdown < 0 && (
                  <>
                    <div className="text-3xl font-bold text-blue-900 mb-4">
                      Recording Mic Check
                    </div>
                    <div className="text-8xl font-mono font-bold text-red-600 mb-6">
                      {Math.abs(micCheckCountdown)}
                    </div>
                    <p className="text-xl text-blue-700 mb-8">
                      Speak normally at your regular volume.<br />
                      Say: "Testing 1 2 3 4 5"
                    </p>
                  </>
                  )}
                  {micCheckPlayback && (
                  <>
                    <div className="text-3xl font-bold text-blue-900 mb-4">
                      Playback
                    </div>
                    <div className="text-xl text-blue-700">
                      Listen to your recording...
                    </div>
                  </>
                  )}
                  {micCheckCountdown === 0 && !micCheckPlayback && (
                  <>
                    <div className="text-3xl font-bold text-blue-900 mb-4">
                      Analyzing...
                    </div>
                    <p className="text-xl text-blue-700">
                      Processing your audio...
                    </p>
                  </>
                  )}
                </div>
              )}
              
              {/* Mic Check Analysis Results */}
              {micCheckAnalysis && (
                <div className="w-full max-w-2xl">
                  <div className={`p-6 rounded-lg border-2 ${
                    micCheckAnalysis.status === 'good' ? 'bg-green-50 border-green-400' :
                    micCheckAnalysis.status === 'clipping' ? 'bg-red-50 border-red-400' :
                    'bg-amber-50 border-amber-400'
                  }`}>
                    <div className="text-center space-y-4">
                      <div className="text-2xl font-bold">
                        {micCheckAnalysis.message}
                      </div>
                      <p className="text-base whitespace-pre-line text-left max-w-lg mx-auto">
                        {micCheckAnalysis.suggestion}
                      </p>
                      {micCheckAnalysis.requireRedo ? (
                        <Button 
                          onClick={handleMicCheck}
                          className="bg-primary text-primary-foreground hover:bg-primary/90 text-lg px-8 py-6"
                        >
                          Try Mic Check Again
                        </Button>
                      ) : (
                        <Button 
                          onClick={() => setMicCheckAnalysis(null)}
                          className="bg-primary text-primary-foreground hover:bg-primary/90 text-lg px-8 py-6"
                        >
                          Start Recording
                        </Button>
                      )}
                    </div>
                  </div>
                </div>
              )}
            </div>
          ) : !micCheckCompleted && !hasPreview ? (
            /* Show prominent mic check button before first use */
            <div className="min-h-[600px] flex flex-col items-center justify-center space-y-8">
              <div className="text-center max-w-2xl mx-auto space-y-6">
                <div className="text-6xl mb-4">üéôÔ∏è</div>
                <h2 className="text-3xl font-bold text-foreground">Test Your Microphone First</h2>
                      Get Ready...
                      ÔøΩÔ∏è Get Ready...
                    </div>
                    <div className="text-8xl font-mono font-bold text-blue-600 mb-6">
                      {micCheckCountdown}
                    </div>
                    <p className="text-xl text-blue-700 mb-8">
                      Starting mic check in {micCheckCountdown}...<br />
                      <span className="text-base">Listen for the beeps!</span>
                    </p>
                  </>
                ) : micCheckCountdown < 0 ? (
                  <>
                    <div className="text-3xl font-bold text-blue-900 mb-4">
                      Recording Mic Check
                    </div>
                    <div className="text-8xl font-mono font-bold text-red-600 mb-6">
                      {Math.abs(micCheckCountdown)}
                    </div>
                    <p className="text-xl text-blue-700 mb-8">
                      Speak normally at your regular volume.<br />
                      Say: "Testing 1 2 3 4 5"
                    </p>
                  </>
                ) : micCheckPlayback ? (
                  <>
                    <div className="text-3xl font-bold text-green-900 mb-4">
                      üîä Playing Back Your Audio
                    </div>
                    <p className="text-xl text-green-700 mt-4 mb-8">
                      Listen to make sure your microphone is working correctly
                    </p>
                    <Loader2 className="w-16 h-16 animate-spin mx-auto text-green-600" />
                  </>
                ) : (
                  <>
                    <div className="text-3xl font-bold text-blue-900 mb-4">
                      üé§ Recording Mic Check
                    </div>
                    <div className="text-6xl font-mono font-bold text-red-600 mb-6 animate-pulse">
                      ‚óè REC
                    </div>
                    <p className="text-xl text-blue-700 mb-8">
                      Speak normally and watch the meter below.<br />
                      Aim for the green zone (50-80%)
                    </p>
                  </>
                )}
              </div>
              )}
              
              {/* Simple instruction text during mic check recording */}
              {!micCheckAnalysis && micCheckCountdown < 0 && (
                <div className="text-center">
                  <p className="text-lg text-muted-foreground">
                    Keep speaking naturally...
                  </p>
                </div>
              )}
              
              {/* Mic Check Analysis Results */}
              {micCheckAnalysis && (
                <div className="w-full max-w-2xl">
                  <div className={`p-6 rounded-lg border-2 ${
                    micCheckAnalysis.status === 'good' ? 'bg-green-50 border-green-400' :
                    micCheckAnalysis.status === 'clipping' ? 'bg-red-50 border-red-400' :
                    'bg-amber-50 border-amber-400'
                  }`}>
                    <div className="text-center space-y-4">
                      <div className="text-2xl font-bold">
                        {micCheckAnalysis.message}
                      </div>
                      <p className="text-base whitespace-pre-line text-left max-w-lg mx-auto">
                        {micCheckAnalysis.suggestion}
                      </p>
                      {micCheckAnalysis.requireRedo ? (
                        <Button 
                          onClick={handleMicCheck}
                          className="bg-primary text-primary-foreground hover:bg-primary/90 text-lg px-8 py-6"
                        >
                          Try Mic Check Again
                        </Button>
                      ) : (
                        <Button 
                          onClick={() => setMicCheckAnalysis(null)}
                          className="bg-primary text-primary-foreground hover:bg-primary/90 text-lg px-8 py-6"
                        >
                          Start Recording
                        </Button>
                      )}
                    </div>
                  </div>
                </div>
              )}
            </div>
          ) : !micCheckCompleted && !hasPreview ? (
            /* Show prominent mic check button before first use */
            <div className="min-h-[600px] flex flex-col items-center justify-center space-y-8">
              <div className="text-center max-w-2xl mx-auto space-y-6">
                <div className="text-6xl mb-4">üéôÔ∏è</div>
                <h2 className="text-3xl font-bold text-foreground">Test Your Microphone First</h2>
                <p className="text-lg text-muted-foreground">
                  Before recording, let's make sure your microphone is working properly.<br />
                  This quick 5-second test will help you avoid recording issues.
                </p>
                
                {/* Microphone selection */}
                <div className="max-w-md mx-auto pt-4">
                  <Label htmlFor="micSelect" className="flex items-center justify-center gap-2 mb-2">
                    <span className="text-lg">Select Your Microphone</span>
                    {selectedDeviceId && devices.filter(d => d.deviceId).length > 0 && (
                      <span className="text-sm font-normal text-emerald-600 flex items-center gap-1">
                        <CheckCircle className="w-4 h-4" /> Ready
                      </span>
                    )}
                  </Label>
                  {devices.filter(d => d.deviceId).length === 0 && (
                    <div className="flex items-center justify-center gap-2 mb-3">
                      <p className="text-sm text-muted-foreground">First, allow microphone access ‚Üí</p>
                      <Button 
                        variant="outline" 
                        size="sm"
                        onClick={() => ensurePermissionAndDevices().catch(() => {})}
                        className="whitespace-nowrap"
                      >
                        <Mic className="w-3 h-3 mr-1" /> Allow Access
                      </Button>
                    </div>
                  )}
                  <Select 
                    value={selectedDeviceId || undefined} 
                    onValueChange={onChangeDevice} 
                    onOpenChange={async (open)=>{ 
                      if(open && devices.filter(d=>d.deviceId).length===0) {
                        try {
                          await ensurePermissionAndDevices();
                        } catch (e) {
                          console.error('Failed to get microphone devices:', e);
                        }
                      }
                    }} 
                    aria-label="Select microphone"
                  >
                    <SelectTrigger id="micSelect" className="text-base h-12">
                      <SelectValue placeholder="Select microphone (allow access first)" />
                    </SelectTrigger>
                    <SelectContent>
                      {devices.filter(d=>d.deviceId).length === 0 ? (
                        <SelectItem value="no-devices" disabled>No microphones found - click to grant access</SelectItem>
                      ) : (
                        devices.filter(d=>d.deviceId).map((d) => (
                          <SelectItem key={d.deviceId} value={d.deviceId}>
                            {d.label || `Microphone ${d.deviceId.slice(0, 8)}...`}
                          </SelectItem>
                        ))
                      )}
                    </SelectContent>
                  </Select>
                </div>

                {/* Big mic check button */}
                <div className="pt-6">
                  <Button 
                    size="lg"
                    className="h-32 w-32 rounded-full text-xl font-bold bg-blue-600 hover:bg-blue-500 text-white shadow-2xl transform transition-transform hover:scale-105"
                    disabled={!selectedDeviceId || isRecording || isMicChecking}
                    onClick={async ()=>{
                      if (devices.length===0) {
                        try { await ensurePermissionAndDevices(); } catch {}
                      }
                      handleMicCheck();
                    }}
                    title="Test your microphone for 5 seconds. Speak normally and watch the input level meter."
                  >
                    <span className="flex flex-col items-center gap-2">
                      <Mic className="w-8 h-8" />
                      <span>Start<br/>Mic Check</span>
                    </span>
                  </Button>
                </div>
                
                <p className="text-sm text-muted-foreground pt-4">
                  üí° During the test, speak at your normal volume and watch for the green zone (50-80%)
                </p>
              </div>
            </div>
          ) : (
            <>
              {/* Normal recording interface - only shown after mic check */}
          {/* Help banner */}
          {!hasPreview && !isRecording && (
            <div className="bg-blue-50 border border-blue-200 rounded-lg p-4 text-sm">
              <div className="flex items-start gap-3">
                <span className="text-2xl">üéôÔ∏è</span>
                <div className="flex-1">
                  <p className="font-medium text-blue-900 mb-2">Quick Start Guide</p>
                  <ol className="list-decimal list-inside space-y-1 text-blue-800">
                    <li><strong>Click Record</strong> - Green button starts recording after 3-second countdown</li>
                    <li><strong>Pause anytime</strong> - Click the button again to pause, click again to resume</li>
                    <li><strong>Stop when paused</strong> - Pause first, then click Stop to finish</li>
                    <li><strong>Preview & Save</strong> - Listen to your recording, then save to your library</li>
                  </ol>
                  <p className="mt-2 text-xs text-blue-700">
                    üí° Hover over any ‚ìò icon for detailed help ‚Ä¢ 
                    <button 
                      onClick={() => setMicCheckCompleted(false)} 
                      className="ml-1 underline hover:text-blue-900"
                    >
                      Run mic check again
                    </button>
                  </p>
                </div>
              </div>
            </div>
          )}
          {supportError && (
            <div className="text-sm bg-red-50 border border-red-200 text-red-700 rounded p-3">
              {supportError}
            </div>
          )}
          {/* Center controls */}
          <div className="flex flex-col items-center gap-5">
            <div className="flex items-center gap-4">
              <Button
                onClick={handleRecordToggle}
                aria-label={!isRecording ? (isCountingDown ? 'Cancel countdown' : 'Start recording') : (isPaused ? 'Resume recording' : 'Pause recording')}
                title={!isRecording ? 'Click to start recording. You\'ll have a 3-second countdown to get ready.' : (isPaused ? 'Click to resume recording from where you paused.' : 'Click to pause recording. You can resume or stop (while paused) to finish.')}
                className={`rounded-full w-28 h-28 text-lg font-semibold shadow ${!isRecording ? (isCountingDown ? 'bg-amber-600 hover:bg-amber-500' : 'bg-green-600 hover:bg-green-500') : (isPaused ? 'bg-green-600 hover:bg-green-500' : 'bg-amber-600 hover:bg-amber-500')} text-white focus-visible:ring-2 focus-visible:ring-offset-2 focus-visible:ring-primary`}
              >
                {!isRecording ? (
                  <span className="flex flex-col items-center leading-tight">
                    <Mic className="w-5 h-5 mb-1" />
                    <span>{isCountingDown ? `Starting in ${countdown}‚Ä¶` : 'Record'}</span>
                  </span>
                ) : (
                  <span className="flex flex-col items-center leading-tight">
                    {isPaused ? (
                      <>
                        <Mic className="w-5 h-5 mb-1" />
                        <span>{isCountingDown ? `Resuming in ${countdown}‚Ä¶` : 'Resume'}</span>
                      </>
                    ) : (
                      <span>Pause</span>
                    )}
                  </span>
                )}
              </Button>
              <Button 
                variant="outline" 
                disabled={!isPaused || isCountingDown} 
                onClick={handleStop} 
                aria-label="Stop recording (available when paused)" 
                title="Stop button is only available when recording is paused. This prevents accidental stops. Pause first, then click Stop to finish your recording."
                className="h-10"
              >
                <Square className="w-4 h-4 mr-2" /> Stop
              </Button>
            </div>

            {/* Digital timer */}
            <div className="text-5xl font-mono tracking-wider" aria-live="polite">{formatTime(elapsed)}</div>

            {/* Mobile keep-awake hint */}
            {isRecording && isMobile && (
              <div className="text-xs text-amber-800 bg-amber-50 border border-amber-200 rounded px-3 py-2" role="status">
                Keep your screen on while recording. We‚Äôll try to prevent sleep.
              </div>
            )}

            {/* Input level meter - simple activity display */}
            <div className="w-full max-w-md">
              <div className="text-sm text-muted-foreground mb-2">
                Microphone Activity
              </div>
              <div className="h-10 rounded-lg bg-slate-900 relative overflow-hidden border-2 border-slate-700">
                {/* Active level bar */}
                <div 
                  className="absolute left-0 top-0 h-full" 
                  style={{ 
                    width: `${Math.round(levelPct*100)}%`,
                    backgroundColor: levelColor,
                    transition: 'width 0.15s linear, background-color 0.3s ease-out'
                  }} 
                />
              </div>
              <div className="flex justify-between items-center text-xs mt-1">
                <span className="text-muted-foreground">
                  {levelPct > 0.15 ? 'üé§ Recording audio' : 'üîá No audio detected'}
                </span>
                <span className="font-mono text-muted-foreground">
                  {Math.round(levelPct * 100)}%
                </span>
              </div>
            </div>
          </div>

          {/* Microphone select - only shown after mic check */}
          <div className="max-w-3xl mx-auto w-full">
            <div className="flex items-center gap-2 mb-2">
              <Label htmlFor="micSelect2" className="flex items-center gap-2">
                Microphone
                {selectedDeviceId && devices.filter(d => d.deviceId).length > 0 && (
                  <span className="text-xs font-normal text-emerald-600 flex items-center gap-1">
                    <CheckCircle className="w-3 h-3" /> Ready
                  </span>
                )}
              </Label>
              <button 
                onClick={() => setMicCheckCompleted(false)} 
                className="text-xs text-blue-600 hover:text-blue-800 underline"
                title="Run mic check again"
              >
                Run mic check again
              </button>
            </div>
            <Select 
              value={selectedDeviceId || undefined} 
              onValueChange={onChangeDevice} 
              aria-label="Select microphone"
            >
              <SelectTrigger id="micSelect2" className="focus-visible:ring-2 focus-visible:ring-offset-2 focus-visible:ring-primary">
                <SelectValue placeholder="Select microphone" />
              </SelectTrigger>
              <SelectContent>
                {devices.filter(d=>d.deviceId).map((d) => (
                  <SelectItem key={d.deviceId} value={d.deviceId}>
                    {d.label || `Microphone ${d.deviceId.slice(0, 8)}...`}
                  </SelectItem>
                ))}
              </SelectContent>
            </Select>
          </div>
          </>
          )}

          {/* Preview & save area (shown after stop) */}
          {hasPreview && (
            <div className="mt-2 space-y-4 max-w-3xl mx-auto w-full">
              <div className="p-4 border rounded-lg bg-card">
                <div className="flex items-center justify-between mb-2">
                  <span className="text-sm font-medium text-muted-foreground">Preview your recording</span>
                  <span 
                    className="text-sm text-muted-foreground cursor-help inline-flex items-center justify-center p-1 hover:bg-slate-100 rounded-full transition-colors" 
                    title="Listen to your recording before saving. Use the audio controls to check quality. Tip: Press Space to play/pause."
                  >
                    ‚ìò
                  </span>
                </div>
                <audio controls className="w-full focus-visible:outline focus-visible:outline-2 focus-visible:outline-primary" src={audioUrl || undefined} ref={audioRef} aria-label="Recording preview" />
              </div>
              <div className="grid md:grid-cols-3 gap-4 items-end">
                <div className="md:col-span-2">
                  <Label htmlFor="recName" className="flex items-center gap-2">
                    Name this recording
                    <span 
                      className="text-sm font-normal text-muted-foreground cursor-help inline-flex items-center justify-center p-1 hover:bg-slate-100 rounded-full transition-colors" 
                      title="Give your recording a descriptive name so you can find it later. Examples: 'Episode 5 - raw', 'Interview with Sarah', 'Intro take 2'"
                    >
                      ‚ìò
                    </span>
                  </Label>
                  <Input id="recName" className="mt-1 focus-visible:ring-2 focus-visible:ring-offset-2 focus-visible:ring-primary" placeholder="e.g., Interview with Jamie (raw)" value={recordingName} onChange={(e)=>setRecordingName(e.target.value)} />
                </div>
                <div className="flex gap-2 md:justify-end">
                  <Button
                    variant="outline"
                    className="flex-1 md:flex-none focus-visible:ring-2 focus-visible:ring-offset-2 focus-visible:ring-primary"
                    title="Download a local copy of your recording as a WAV file. This is optional - you can save directly to your library without downloading."
                    onClick={() => {
                      if (!audioUrl || !audioRef.current) return;
                      const link = document.createElement('a');
                      link.href = audioUrl;
                      link.download = `${recordingName || 'recording'}.wav`;
                      document.body.appendChild(link);
                      link.click();
                      document.body.removeChild(link);
                    }}
                    disabled={!audioUrl}
                  >
                    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round" className="mr-2"><path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"/><polyline points="7 10 12 15 17 10"/><line x1="12" y1="15" x2="12" y2="3"/></svg>
                    Download
                  </Button>
                  <Button
                    className="flex-1 md:flex-none focus-visible:ring-2 focus-visible:ring-offset-2 focus-visible:ring-primary"
                    aria-label="Save and continue"
                    title="Upload this recording to your media library and start automatic transcription. You'll receive an email when it's ready to use in an episode."
                    disabled={!audioBlob || isSaving || (audioBlob && audioBlob.size > MAX_UPLOAD_BYTES) || !!serverFilename}
                    onClick={handleSave}
                  >
                    {isSaving ? (
                      <span className="inline-flex items-center gap-2"><Loader2 className="h-4 w-4 animate-spin" /> Saving‚Ä¶</span>
                    ) : (!!serverFilename ? 'Saved' : 'Save and continue')}
                  </Button>
                  <Button 
                    variant="outline" 
                    className="flex-1 md:flex-none focus-visible:ring-2 focus-visible:ring-offset-2 focus-visible:ring-primary" 
                    aria-label="Discard recording" 
                    title="Delete this recording and start over. Warning: This cannot be undone!"
                    disabled={isSaving} 
                    onClick={()=>{ setHasPreview(false); setAudioBlob(null); setAudioUrl((u)=>{ if(u) URL.revokeObjectURL(u); return ""; }); setRecordingName(""); }}
                  >
                    Discard
                  </Button>
                </div>
              </div>
              {audioBlob && audioBlob.size > MAX_UPLOAD_BYTES && (
                <div className="text-sm bg-red-50 border border-red-200 text-red-700 rounded p-3">
                  Recording too long to upload (over 500 MB). Please record a shorter segment.
                </div>
              )}
              {serverFilename && (
                <div className="p-4 border rounded-lg bg-muted/30">
                  <div className="flex items-center justify-between gap-3 flex-wrap">
                    <div>
                      <div className="text-sm text-muted-foreground">Queued for processing</div>
                      <div className="text-sm font-medium mt-1">{savedDisplayName || serverFilename}</div>
                      <div className="text-xs text-muted-foreground mt-0.5">
                        Size: {audioBlob ? (audioBlob.size / (1024*1024)).toFixed(2) : '0.00'} MB
                      </div>
                    </div>
                    <div className="flex items-center gap-3">
                      {transcriptReady ? (
                        <span className="inline-flex items-center px-3 py-1 rounded-full text-xs font-medium bg-emerald-100 text-emerald-800 border border-emerald-200">
                          <CheckCircle className="h-4 w-4 mr-1" aria-hidden /> Ready
                        </span>
                      ) : (
                        <span className="inline-flex items-center px-3 py-1 rounded-full text-xs font-medium bg-amber-100 text-amber-800 border border-amber-200">
                          <Loader2 className="h-4 w-4 mr-1 animate-spin" aria-hidden /> Processing‚Ä¶
                        </span>
                      )}
                    </div>
                  </div>
                  
                  {/* Prominent download button - available for 24 hours */}
                  {audioUrl && audioBlob && (
                    <div className="border-t pt-3 mt-3">
                      <div className="text-xs text-muted-foreground mb-2">
                        üíæ <strong>Save a backup copy!</strong> Download link available for 24 hours.
                      </div>
                      <Button
                        onClick={() => {
                          const a = document.createElement("a");
                          a.href = audioUrl;
                          a.download = savedDisplayName || recordingName || "recording.webm";
                          document.body.appendChild(a);
                          a.click();
                          document.body.removeChild(a);
                        }}
                        variant="outline"
                        className="w-full sm:w-auto"
                      >
                        <Download className="w-4 h-4 mr-2" />
                        Download Raw Recording
                      </Button>
                    </div>
                  )}

                  <div className="flex items-center justify-between gap-3 flex-wrap mt-3">
                    <div></div>
                    <div className="flex items-center gap-3">
                      {transcriptReady && (
                        <Button
                          className="bg-primary text-primary-foreground hover:bg-primary/90 focus-visible:ring-2 focus-visible:ring-offset-2 focus-visible:ring-primary"
                          aria-label="Finish episode"
                          onClick={() => {
                            // Prefer prop callback handoff; fallback to localStorage + event for backward-compat
                            if (typeof onFinish === 'function') {
                              onFinish({ filename: serverFilename, hint: serverStem, transcriptReady: true, startStep: 5 });
                              return;
                            }
                            try {
                              if (serverFilename) localStorage.setItem('ppp_uploaded_filename', serverFilename);
                              if (serverStem) localStorage.setItem('ppp_uploaded_hint', serverStem);
                              localStorage.setItem('ppp_start_step', '5');
                              localStorage.setItem('ppp_transcript_ready', '1');
                            } catch {}
                            try {
                              window.dispatchEvent(new CustomEvent('ppp:navigate-view', { detail: 'createEpisode' }));
                            } catch {}
                          }}
                        >
                          Finish Episode
                        </Button>
                      )}
                    </div>
                  </div>
                  {showTimeoutNotice && !transcriptReady && (
                    <div className="text-xs text-muted-foreground mt-3">Still processing; you can leave this page ‚Äî we‚Äôll keep working.</div>
                  )}
                </div>
              )}
            </div>
          )}
        </CardContent>
      </Card>
      </div>
    </>
  );
}
